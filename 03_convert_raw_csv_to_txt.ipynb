{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Convert Raw Table Sheet Annotations to txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input = 'input.csv' # Diese Stelle austauschen je nachdem, welche csv konvertiert werden soll\n",
    "path_output = './'\n",
    "df = pd.read_csv(path_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 'location general', 'food prices', 'food quality', 'food general',\n",
    "#     'ambience general', 'service general', 'restaurant prices',\n",
    "#     'drinks prices', 'restaurant miscellaneous', 'drinks quality',\n",
    "#     'drinks style_options', 'restaurant general', 'food style_options'\n",
    "\n",
    "AC = {\n",
    "    \"loca\": \"location general\",\n",
    "    \"location\": \"location general\",\n",
    "    \"serv\": \"service general\",\n",
    "    \"foodq\": \"food quality\",\n",
    "    \"foodg\": \"food general\",\n",
    "    \"amb\": \"ambience general\",\n",
    "    \"drinkq\": \"drinks quality\",\n",
    "    \"restaurantp\": \"restaurant prices\",\n",
    "    \"foodp\": \"food prices\",\n",
    "    \"drinkp\": \"drinks prices\",\n",
    "    \"restaurantm\": \"restaurant miscellaneous\",\n",
    "    \"drinks\": \"drinks style_options\",\n",
    "    \"foods\": \"food style_options\",\n",
    "    \"restaurantg\": \"restaurant general\"\n",
    "}\n",
    "\n",
    "POL = {\n",
    "    \"pos\": \"positive\",\n",
    "    \"neg\": \"negative\",\n",
    "    \"neu\": \"neutral\"\n",
    "}\n",
    "\n",
    "\n",
    "def convert_aspects(aspects_raw, text):\n",
    "    aspects = []\n",
    "    for aspect in aspects_raw:\n",
    "\n",
    "        if aspect[0] not in text and aspect[0] != \"NULL\":\n",
    "            print(\n",
    "                f\"##### ERROR: Aspect term '{aspect[0]}' not found in text:\", text)\n",
    "        if aspect[1] not in AC.keys():\n",
    "            print(f\"##### ERROR: Aspect category {aspect} not found:\", text)\n",
    "        if aspect[2] not in POL.keys():\n",
    "            print(\n",
    "                f\"##### ERROR: Aspect sentiment {aspect[2]} not found in:\", text)\n",
    "        if aspect[3] not in text:\n",
    "            print(\n",
    "                f\"##### ERROR: Opinion term '{aspect[3]}' not found in text:\", text)\n",
    "\n",
    "        aspects.append([aspect[0], AC[aspect[1]], POL[aspect[2]], aspect[3]])\n",
    "    return aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\n",
    "\n",
    "total_empty = 0\n",
    "total_anonym = 0\n",
    "total_more_than_one = 0\n",
    "total_more_than_one_sentence = 0\n",
    "total_examples = 0\n",
    "total_valid_examples = 0\n",
    "total_not_english = 0\n",
    "total_can_t_be_understood = 0\n",
    "\n",
    "\n",
    "def process_aspect_text(aspect_text):\n",
    "    \"\"\"\n",
    "    Teilt den Eingabetext basierend auf Kommas, behÃ¤lt maximal 3 Substrings pro Eintrag\n",
    "    und verbindet die restlichen, wenn mehr als 4 Substrings existieren.\n",
    "\n",
    "    :param aspect_text: str, Eingabetext, z.B. \"Aspect1, Aspect2, Aspect3, Aspect4, Aspect5\"\n",
    "    :return: list, verarbeitete Liste von Strings\n",
    "    \"\"\"\n",
    "    processed_list = [s for s in re.split(r',', aspect_text)]\n",
    "\n",
    "    if len(processed_list) > 4:\n",
    "        processed_list = processed_list[:3] + [','.join(processed_list[3:])]\n",
    "    processed_list = [s.strip() for s in processed_list]\n",
    "\n",
    "    return processed_list\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    rows = row.tolist()\n",
    "    entry_text = rows[0]\n",
    "\n",
    "    all_raw_lists = []\n",
    "    for aspect_text in rows[2:16]:\n",
    "        try:\n",
    "            raw_list = process_aspect_text(aspect_text)\n",
    "            all_raw_lists.append(raw_list)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # 1. Count all examples without aspects\n",
    "    no_aspects = False\n",
    "    if len(all_raw_lists) == 0:\n",
    "        no_aspects = True\n",
    "        total_empty += 1\n",
    "\n",
    "    # 2. Count all examples that are not anoymized\n",
    "    anonym_found = False\n",
    "    for sublist in all_raw_lists:\n",
    "        if \"anonym\" in sublist:\n",
    "            if not anonym_found:\n",
    "                total_anonym += 1\n",
    "                anonym_found = True\n",
    "            break\n",
    "\n",
    "    # 3. Count all examples that are not english\n",
    "    not_english_found = False\n",
    "    for sublist in all_raw_lists:\n",
    "        if \"not english\" in sublist:\n",
    "            if not not_english_found:\n",
    "                total_not_english += 1\n",
    "                not_english_found = True\n",
    "            break\n",
    "\n",
    "    # 4. Count all examples with more than one sentence\n",
    "    more_than_one_sentence_found = False\n",
    "    for sublist in all_raw_lists:\n",
    "        if \"more than 1 sentence\" in sublist:\n",
    "            if not more_than_one_sentence_found:\n",
    "                total_more_than_one_sentence += 1\n",
    "                more_than_one_sentence_found = True\n",
    "            break\n",
    "\n",
    "    # 5. Count all \"can't be understood\"\n",
    "    cant_be_understood_found = False\n",
    "    for sublist in all_raw_lists:\n",
    "        if \"can't be understood\" in sublist:\n",
    "            if not cant_be_understood_found:\n",
    "                total_can_t_be_understood += 1\n",
    "                cant_be_understood_found = True\n",
    "            break\n",
    "\n",
    "    if (no_aspects or anonym_found or more_than_one_sentence_found or not_english_found or cant_be_understood_found):\n",
    "        pass\n",
    "    else:\n",
    "        # 5. Check for examples with < 4 sentiment elements\n",
    "        has_four_elements = True\n",
    "        for sublist in all_raw_lists:\n",
    "            if len(sublist) < 4:\n",
    "                print(\"##### ERROR:\", entry_text, sublist)\n",
    "                has_four_elements = False\n",
    "\n",
    "        if has_four_elements == True:\n",
    "            aspects = convert_aspects(all_raw_lists, entry_text)\n",
    "            data += entry_text + \"####\" + str(aspects) + \"\\n\"\n",
    "            total_valid_examples += 1\n",
    "\n",
    "    # print(all_raw_lists)\n",
    "\n",
    "    total_examples += 1\n",
    "\n",
    "print(\"Empty:\", total_empty)\n",
    "print(\"Anonymized:\", total_anonym)\n",
    "print(\"More than 1 sentence:\", total_more_than_one_sentence)\n",
    "print(\"Valid examples:\", total_valid_examples)\n",
    "print(\"Not English:\", total_not_english)\n",
    "print(\"Can't be understood\", total_can_t_be_understood)\n",
    "print(\"-----\")\n",
    "print(total_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_output+\".txt\", 'w', encoding='utf-8') as file:\n",
    "    file.write(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
